{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10457515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sddpg\n",
    "import ddpg\n",
    "from memory import ReplayMemory\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordEpisodeStatistics, RecordVideo\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31aeb52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "safe = True\n",
    "training = True\n",
    "path = 'models/sddpg_cheetah.pt'\n",
    "file_name = \"sddpg_cheetah\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fef4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a539ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "N_EPISODES = 50\n",
    "BATCH_SIZE = 128\n",
    "MEMORY_SIZE = 10000\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 100\n",
    "WEIGHT_DECAY = 0.005\n",
    "TAU = 1e-3\n",
    "LR = 1e-4\n",
    "\n",
    "max_steps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07018d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"HalfCheetah-v5\", render_mode='rgb_array', max_episode_steps=max_steps)\n",
    "env = gym.wrappers.NumpyToTorch(env, device=device)\n",
    "n_actions = env.action_space.shape[0] \n",
    "state, _ = env.reset()\n",
    "\n",
    "n_obs = len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65542691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(episode, eps_start, eps_end, eps_decay, criterion_critic, agent, memory, env, device=torch.device(\"cpu\")):\n",
    "    state, info = env.reset()\n",
    "    state = state.float().unsqueeze(0)\n",
    "\n",
    "    if isinstance(agent, sddpg.SDDPG):\n",
    "        x0 = torch.zeros_like(state)\n",
    "        x0.copy_(state)\n",
    "        x0 = x0.to(device)\n",
    "        agent.set_init(x0)\n",
    "\n",
    "    episode_reward = 0\n",
    "    max_vel = 0\n",
    "    while True:\n",
    "        # Select an action in the current state and\n",
    "        # add the resulting observations to the\n",
    "        # memory buffer\n",
    "        eps = eps_end + (eps_start - eps_end) * math.exp(-1. * episode / eps_decay)\n",
    "\n",
    "        if random.random()<eps:\n",
    "            action = torch.tensor(env.action_space.sample()).to(device)\n",
    "\n",
    "        else:\n",
    "            action = agent.select_action(state)\n",
    "\n",
    "        observation, reward, terminated, truncated, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        reward = torch.tensor([reward], device=device, dtype=torch.float32)\n",
    "        done = terminated or truncated\n",
    "        max_vel = max(np.abs(observation[1]), max_vel)\n",
    "        next_state = None if terminated else observation.float().unsqueeze(0)\n",
    "        memory.push(state, action.unsqueeze(0), next_state, reward)\n",
    "\n",
    "        state = next_state\n",
    "        agent.update(memory, criterion_critic)\n",
    "\n",
    "        if done:\n",
    "            return episode_reward, max_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8955d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(x: torch.tensor):\n",
    "    return (torch.abs(x[:,1])<=np.pi/4).unsqueeze(-1).to(device)\n",
    "\n",
    "d0 = 50\n",
    "\n",
    "# Training loop\n",
    "if safe:\n",
    "    agent = sddpg.SDDPG(n_obs, n_actions, BATCH_SIZE, GAMMA, TAU, LR, WEIGHT_DECAY,d, d0, state, device=device)\n",
    "else:\n",
    "    agent = ddpg.DDPG(n_obs, n_actions, BATCH_SIZE, GAMMA, TAU, LR, WEIGHT_DECAY, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab8ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_798163/3307582412.py:29: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  max_vel = max(np.abs(observation[1]), max_vel)\n",
      " 58%|█████▊    | 29/50 [03:25<02:29,  7.12s/it, average last 5 rewards=-63.1, max_vel=3.46]"
     ]
    }
   ],
   "source": [
    "if training:\n",
    "    if path is not None:\n",
    "        agent.load(path)\n",
    "    criterion_critic = nn.MSELoss()\n",
    "    memory = ReplayMemory(MEMORY_SIZE)\n",
    "    losses = []\n",
    "\n",
    "    for i_episode in (pbar := tqdm(range(N_EPISODES))):\n",
    "        episode_reward, max_vel = train(i_episode, EPS_START, EPS_END, EPS_DECAY, criterion_critic, agent, memory, env, device=device)\n",
    "        losses.append(episode_reward)\n",
    "        pbar.set_postfix({\n",
    "                    'average last 5 rewards': round(losses[i_episode], 5),\n",
    "                    'max_vel': round(max_vel.item(), 3),\n",
    "                    })\n",
    "\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "    fig = plt.figure()\n",
    "    ax  = fig.subplots(1)\n",
    "    ax.plot(losses)\n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.set_ylabel(\"Reward\")\n",
    "    fig.suptitle(\"Training Reward over time (DDPG)\")\n",
    "    if os.path.isdir('figures') is False:\n",
    "                os.mkdir('figures')\n",
    "    fig.savefig(f\"figures/{file_name}_losses.png\")\n",
    "    print(\"Saving model...\")\n",
    "    agent.save(file_name)\n",
    "    print(\"Saved Model Weights!\")\n",
    "else:\n",
    "    assert path is not None\n",
    "    agent.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval_episodes=5\n",
    "# env = RecordEpisodeStatistics(env, buffer_length=num_eval_episodes)\n",
    "# env = RecordVideo(env, video_folder=\"video_renders\", name_prefix=f\"cheetah_{file_name}\", episode_trigger=lambda _: True)\n",
    "fig = plt.figure()\n",
    "ax  = fig.subplots(1)\n",
    "velocities = np.zeros((num_eval_episodes, max_steps))\n",
    "for episode_num in range(num_eval_episodes):\n",
    "    obs, _ = env.reset()\n",
    "    x0 = obs.float().unsqueeze(0)\n",
    "\n",
    "    done = False\n",
    "    t=0\n",
    "    if(isinstance(agent, sddpg.SDDPG)):\n",
    "        agent.set_init(x0)\n",
    "    while not done:\n",
    "        state = obs.unsqueeze(0).float()\n",
    "        action = agent.select_action(state)\n",
    "\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        velocities[episode_num, t] = obs[1].item()\n",
    "        t+=1\n",
    "\n",
    "T = np.arange(0,max_steps)\n",
    "\n",
    "mean_vol = np.mean(velocities,axis=0)\n",
    "max_vol = np.max(velocities,axis=0)\n",
    "min_vol = np.min(velocities, axis=0)\n",
    "\n",
    "\n",
    "ax.plot(T,mean_vol, 'b-', label='angle mean')\n",
    "ax.fill_between(T, min_vol, max_vol, alpha=0.5)\n",
    "ax.plot(T, [np.pi/4]*max_steps, 'k', label='vel Constraint')\n",
    "ax.plot(T, [-np.pi/4]*max_steps, 'k',)\n",
    "\n",
    "ax.set_xlabel(\"Timestep\")\n",
    "ax.set_ylabel(r\"Tip Angle ($\\theta$ radians)\")\n",
    "ax.legend()\n",
    "fig.suptitle(f\"Angle of head from {num_eval_episodes} eval episodes (DPPG)\")\n",
    "if os.path.isdir('figures') is False:\n",
    "    os.mkdir('figures')\n",
    "fig.savefig(f\"figures/{file_name}_velocity.png\")\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
